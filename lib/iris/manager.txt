_lazy_data.py
=============

These functions are imported by cube and used:

as_concrete_data
as_lazy_data
is_lazy_data


cube.py
=======

The cube has the following lazy related methods:

lazy_data
has_lazy_data


class DataManager
=================

State
-----
 + _lazy    # The lazy (dask) array ... steered away for using dask as a name (perhaps we replace dask in future?!)
 + _real    # The real (numpy) array
 + _dtype   # The intended dtype of the realized lazy array.
            # Purpose is to cope with lazy masked integral data.
            # STRECH: Precursor to actual casting support? Needs thought ...
            # Rename this to "_lazy_dtype" or "_realisation_dtype" or other ...

Axiom:
  Either _lazy or _real must be populated at any given time, not both, not neither.

Open Questions:
 + Where does fill_value live?
   - within the owner - supports one fill_value of coordinate points and bounds
   - within the instance - control to reset the fill_value if need be given an opertion.
 + Support both _lazy and _real being populated? Why? What's the use case?
 + Where should the DataManager live? iris.core ? iris._manager ? ...
 + What should we call the DataManager? Suggestions on a postcard ...


Behaviour
---------
 + lazy_data (getter)
   - return _lazy array or return lazifyed _real array         # Issue with lazifying Masked integral
 + has_lazy_data (boolean)
   - is _lazy populated (or _real unpopulated)
 + dtype (getter)
   - return the _dtype OR the _real array dtype OR the _lazy array dtype (in that specific order)
 + data (getter)
   - axiom - on return _lazy array is None, _real array is populated
   - return the _real array, OR
   - realise the _lazy array, assign it as the _real array, clear the _dtype and return _real array
 + data (setter)
   - axiom - _dtype is cleared AND fill_value is cleared (by manager or container owner)
   - contract as per cube.data (setter)
 + copy(data=None, dtype=None [? fill_value=None])
   - calls _deepcopy()
 + __deepcopy__
   - calls _deepcopy()
 + __copy__
   - shallow copies not permitted
 + _deepcopy
   - contract as per cube._deepcopy

The following is suggested new/rebranded behaviour not supported by the current (dask) cube API:

 + any (getter)                                                # named other than core_data ?
   - return populated _real array OR polulated _lazy array (in that specific order)
 + replace(data, dtype=None [? fill_value=None])
   - uses data (setter)
   - _dtype is cleared or set as specified
   ? fill_value is cleared or set as specified
   - supports the use case seen in our testing where the cube payload requires to be replace
     but results in the pattern of caching the fill_value, setting the data, then setting the
     fill_value (as fill_value is cleared on cube.data setting)

The following behaviour is in question as to whether we need to support it

 ? __getstate__
   + support for pickle
 ? __setstate__
   + support for pickle
 ? __eq__
 ? __ne__
 ? __hash__

Usage
=====
 + DataManager is internal to the core of iris and does not bleed out beyond the public API
   i.e. we are not going to support cube.data = DataManager(...) and the likes!

